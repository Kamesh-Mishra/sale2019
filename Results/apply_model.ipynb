{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import sys\n",
    "sys.path.append('../Training/')\n",
    "from res import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../Data/cleanTweets.csv',na_values={'None','NONE'})\n",
    "\n",
    "df=df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df=df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading SVM model\n",
    "sl='../Training/learnWV8_1.sav' \n",
    "Llearn_obj=pickle.load(open(sl,'rb'))\n",
    "\n",
    "#loading Word2Vec model\n",
    "str_='../Training/w2v1_9_ESW5_C_swmod3_s_w2'\n",
    "word2vec_path = str_+\".bin\"\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell computes sentiment class for each tweet and corrosponding confidence score\n",
    "import ast\n",
    "\n",
    "def conf(arg):\n",
    "    return max(arg[0],arg[1],arg[2])\n",
    "\n",
    "df['tokens']=df.apply(lambda arg: ast.literal_eval(arg['tokens']),axis=1)\n",
    "\n",
    "embed = get_word2vec_embeddings(word2vec, df)\n",
    "\n",
    "df['pred']=Llearn_obj.predict(embed) #predicting sentiment class \n",
    "df['conf']=list(map(conf,Llearn_obj.predict_proba(embed))) #computing proability corrosponding to most confident prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf restriction\n",
    "d1=df.loc[df.index[df['pred']=='neu']]\n",
    "d2=df.loc[df.index[df['pred']!='neu']]\n",
    "\n",
    "#using only tweets with confident predictions\n",
    "d1=d1.loc[d1.index[d1['conf']>=0.5]]#for neutral predictions use tweets with atleast 50% confidence (because support value for neutral is less)\n",
    "d2=d2.loc[d2.index[d2['conf']>=0.6]]#for positive and negative predictions use tweets with atleast 60% confidence\n",
    "\n",
    "\n",
    "d1=d1.reset_index(drop=True)\n",
    "d2=d2.reset_index(drop=True)\n",
    "\n",
    "df2=d1.append(d2,ignore_index=True)\n",
    "\n",
    "df2=shuffle(df2)\n",
    "df2=df2.reset_index(drop=True)\n",
    "#df.to_csv('ProsAll_pred_prob2.csv',index=None,header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('../Data/cleanTweets_pred_prob.csv',index=None,header=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
