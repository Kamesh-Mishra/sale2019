{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This program was used to filter tweets on basis of location and tags and then cleaning them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from ast import literal_eval\n",
    "from langdetect import detect_langs\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed=0\n",
    "import fun_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining dictionary list from json file\n",
    "dict_list=[]\n",
    "start_t=time.time()\n",
    "\n",
    "count=0\n",
    "with open('file.json','r') as f:\n",
    "    for el in f:\n",
    "        count=count+1\n",
    "        try:\n",
    "            dict_= json.loads(el)\n",
    "            dict_list.append(dict_)\n",
    "        except:\n",
    "            #dict_list.append(dict_)\n",
    "            print(dict_['id'], count)\n",
    "            #raise\n",
    "            continue\n",
    "\n",
    "print('No of Tweets at input:',len (dict_list))        \n",
    "print('time till forming list of dictionaries from json:',time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming dataframe from list of dict\n",
    "df=pd.DataFrame()\n",
    "for fld in dict_list[0].keys():\n",
    "    if fld!=\"extended_tweet\" and fld!=\"display_text_range\": #because these 2 fields aren't necessarly present in a tweet\n",
    "                                                            #thus they are handled seperately after this loop\n",
    "        df[fld]=list(map(lambda arg:arg[fld],dict_list )) \n",
    "        \n",
    "df['display_text_range']=list(map(lambda arg: literal_eval(arg['display_text_range']) if 'display_text_range' in arg.keys() else None , dict_list ))\n",
    "p=list(map( lambda arg: literal_eval( arg['extended_tweet']) if 'extended_tweet' in arg.keys() else None , dict_list ))\n",
    "df['full_text']= list(map(lambda arg: arg['full_text'] if arg!=None else None , p ))\n",
    "df['display_full_text_range']=list(map(lambda arg: (arg['display_text_range']) if arg!=None else None , p))\n",
    "\n",
    "#adding extra fields that will be used later \n",
    "df['translate']=False   #this field tells weather a tweet is in local language and thus needs translation\n",
    "df['trans_text']='NONE' #contains translated text (In this project no translation was carried out)\n",
    "df['pros_text']='NONE'  #processed text (text after cleaning)\n",
    "df['trans_lang']='NONE' #detected language\n",
    "\n",
    "print('time till forming dataframe from list of dict:',time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering by location (local matching)\n",
    "x= df.apply(fun_.fun_loc, axis=1)\n",
    "logic=list(map( lambda arg: arg[0], x ))\n",
    "trn=list(map( lambda arg: arg[1], x ))\n",
    "logic_=list(map( lambda arg: not arg, logic ))\n",
    "\n",
    "fil_by_loc= df.loc[(df.index[logic])]\n",
    "fil_by_loc['translate']=list(filter( None.__ne__,trn)) \n",
    "rem=df.loc[(df.index[logic_])] #rem means remaining tweets (which were not accepted by above location filter)\n",
    "print('time till filtering by location:',time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering by tags (this is done on remaining tweets from above filter)\n",
    "x=rem.apply(fun_.fun_text, axis=1)\n",
    "logic=list(map( lambda arg: arg[0], x ))\n",
    "trn=list(map( lambda arg: arg[1], x ))\n",
    "logic_=list(map( lambda arg: not arg, logic ))\n",
    "\n",
    "fil_by_tag=rem.loc[(rem.index[logic])]\n",
    "fil_by_tag['translate']=list(filter( None.__ne__,trn))\n",
    "rem2=rem.loc[(rem.index[logic_])]\n",
    "print('time till filtering by tags:',time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweets filtered by tags are further filtered to remove tweets related to foreign tags (like Brexit, US congress etc)\n",
    "logic=fil_by_tag.apply(fun_.fun_foreign , axis=1)\n",
    "logic_=list(map( lambda arg: not arg, logic ))\n",
    "\n",
    "mod_fil_by_tag=fil_by_tag.loc[(fil_by_tag.index[logic])]\n",
    "rem3=fil_by_tag.loc[(fil_by_tag.index[logic_])]\n",
    "print('time till removing foreign tags:',time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_by_loc.to_csv(r'tweetsByLoc.csv',index=None,header=True)\n",
    "mod_fil_by_text.to_csv(r'tweetsByTag.csv',index=None,header=True)\n",
    "rem2.to_csv(r'rem2.csv',index=None,header=True)\n",
    "rem3.to_csv(r'rem3.csv',index=None,header=True)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
